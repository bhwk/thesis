
\begin{abstract}
	The increasing utilization of Large Language Models (LLMs) in healthcare for tasks such as clinical note summarization and medical report generation presents challenges for protecting sensitive patient data. This is particularly important due to the inherent privacy risks associated with the use of proprietary and sensitive information, especially within Retrieval-Augmented Generation (RAG) systems. This project proposes a privacy-focused framework that leverages synthetic document generation to mitigate these risks while maintaining the semantic similarity of generated responses.

	This project evaluates the effectiveness of synthetic document generation in mitigating privacy risks while preserving contextual relevance. Through a series of tests, the system's ability to reduce PII leakage as well as withstand adversarial attacks is evaluated.

	The proposed system follows an agent-based approach, incorporating three key agents: a Search Agent, a Synthesis Agent, and a Review Agent. The process begins with the Search Agent retrieving relevant vector-related text nodes from a vector database. The Synthesis Agent then evaluates the extracted content, filtering and retaining only the necessary information for query responses while removing personally identifiable information (PII). Finally, the Review Agent verifies and refines the synthesized document to ensure privacy compliance before passing it to the LLM.
\end{abstract}
